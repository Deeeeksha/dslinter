<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>data preparation on DSLinter - Linter for Machine Learnig Application - Specific Code Smells</title>
    <link>https://hynn01.github.io/dslinter/tags/data-preparation/</link>
    <description>Recent content in data preparation on DSLinter - Linter for Machine Learnig Application - Specific Code Smells</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://hynn01.github.io/dslinter/tags/data-preparation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>In Place APIs Misused</title>
      <link>https://hynn01.github.io/dslinter/code-smells/in-place-apis-misused/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/in-place-apis-misused/</guid>
      <description>Description “In-place operation is an operation that directly changes the content of a given linear algebra, vector, matrices (Tensor) without making a copy.” Due to the nature of the in-place operation, the in-place APIs are easily misused. Developers sometimes forget to set the in-place parameter in APIs to true while not assigning the new result to a variable, causing potential silent bugs. The data is not updated in this way, but the developer thinks it is and might not be able to find where the bug is.</description>
    </item>
    
    <item>
      <title>Vectorized Solution Unused</title>
      <link>https://hynn01.github.io/dslinter/code-smells/vectorized-solution-unused/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/vectorized-solution-unused/</guid>
      <description>Description &amp;ldquo;Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at one time.&amp;rdquo; ML applications are often data-intensive and need to apply an operation on a dataset. Therefore, it is better to adopt vectorized solution instead of iterating over data. As stated in the Pandas documentation : ”Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed and can be avoided”.</description>
    </item>
    
    <item>
      <title>No Scaling Before Scaling Sensitive Operation</title>
      <link>https://hynn01.github.io/dslinter/code-smells/no-scaling-before-scaling-sensitive-operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/no-scaling-before-scaling-sensitive-operation/</guid>
      <description>Description Principle Component Analysis (PCA) is used for finding the components that maximize the data&amp;rsquo;s variation and reduce its dimensions, which is an essential data processing method. Scaling is pretty crucial to PCA because of the way the principal components are calculated. If one variable is on a larger scale than another, it will dominate the PCA procedure. Similarly, there are some other scaling-sensitive operations. Support Vector Machine (SVM), Stochastic Gradient Descent (SGD), Multi-layer Perceptron classifier, L1 and L2 regularization are all sensitive to feature scaling.</description>
    </item>
    
    <item>
      <title>Data Leakage</title>
      <link>https://hynn01.github.io/dslinter/code-smells/data-leakage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/data-leakage/</guid>
      <description>Description &amp;ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.&amp;rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.</description>
    </item>
    
    <item>
      <title>Hyperparameter Not Set</title>
      <link>https://hynn01.github.io/dslinter/code-smells/hyperparameter-not-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/hyperparameter-not-set/</guid>
      <description>Description Hyperparameters are ML algorithm parameters used to control the learning process and are usually determined before the actual process starts. Hyperparameters should be set and tuned because they improve prediction quality and reproducibility. Tuning hyperparameters can lead to higher prediction quality because the default parameters of the learning algorithm may not be optimal for a given data or problem, and may lead to local optima. These parameters directly control the behavior of the training algorithm and therefore have a significant impact on the performance of the model.</description>
    </item>
    
  </channel>
</rss>
